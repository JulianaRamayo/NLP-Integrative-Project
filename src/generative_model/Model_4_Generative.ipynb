{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "id": "tVazrphgvZPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I40DXni-vUil"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "from joblib import dump, load\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ],
      "metadata": {
        "id": "zFoDxzyyva-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!kaggle datasets download -d kritanjalijain/amazon-reviews -p /content"
      ],
      "metadata": {
        "id": "nhUZbFj5vgX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file_path = '/content/amazon-reviews.zip'\n",
        "extract_dir = '/content/amazon-reviews/'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ],
      "metadata": {
        "id": "9XQhvP9UvfUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/amazon-reviews/train.csv', header=None, names=['polarity', 'title', 'text'])\n",
        "df = df.sample(frac=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "jozIqTh7vjZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir etiquetas a 'positive' y 'negative'\n",
        "df['polarity'] = df['polarity'].apply(lambda x: 'positive' if x == 1 else 'negative')"
      ],
      "metadata": {
        "id": "PAvixkWSv9Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AmazonReviewsDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.df = df\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        text = f\"transform to {'negative' if row['polarity'] == 'positive' else 'positive'}: \" + row['title'] + \" \" + row['text']\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=False\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
        "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
        "            'labels': torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "max_len = 128\n",
        "dataset = AmazonReviewsDataset(df, tokenizer, max_len)\n",
        "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "oOsXejnMv-4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "def train_epoch(model, data_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(data_loader):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ],
      "metadata": {
        "id": "iyewemJzwB1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    train_loss = train_epoch(model, data_loader, optimizer, device)\n",
        "    print(f'Train loss: {train_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "A23k4wgpwDKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_review(model, tokenizer, text, device, target_polarity):\n",
        "    model.eval()\n",
        "    input_text = f\"transform to {target_polarity}: {text}\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors='pt').to(device)\n",
        "    outputs = model.generate(input_ids, max_length=128)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Ejemplo de prueba\n",
        "positive_review = \"The product works perfectly and the service was excellent.\"\n",
        "negative_review = generate_review(model, tokenizer, positive_review, device, \"negative\")\n",
        "print(\"Original:\", positive_review)\n",
        "print(\"Transformed:\", negative_review)\n"
      ],
      "metadata": {
        "id": "RKzg199BwF9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}