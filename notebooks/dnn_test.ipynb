{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d55fc369-07bb-4012-9495-91f192be69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "999366c5-e89a-4bd6-a8f8-d721f85c7d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Sample:\n",
      "   label                            title  \\\n",
      "0      2           stuning even non gamer   \n",
      "1      2    best soundtrack ever anything   \n",
      "2      2                          amazing   \n",
      "3      2             excellent soundtrack   \n",
      "4      2  remember pull jaw floor hearing   \n",
      "\n",
      "                                              review  \n",
      "0  sound track beautiful paint senery mind well w...  \n",
      "1  reading lot review saying best game soundtrack...  \n",
      "2  soundtrack favorite music time hand intense sa...  \n",
      "3  truly like soundtrack enjoy video game music p...  \n",
      "4  played game know divine music every single son...  \n",
      "\n",
      "Testing Data Sample:\n",
      "   label                                            title  \\\n",
      "0      2                                         great cd   \n",
      "1      2  one best game music soundtrack game really play   \n",
      "2      1                         battery died within year   \n",
      "3      2                     work fine maha energy better   \n",
      "4      2                             great non audiophile   \n",
      "\n",
      "                                              review  \n",
      "0  lovely pat one great voice generation listened...  \n",
      "1  despite fact played small portion game music h...  \n",
      "2  bought charger jul worked ok design nice conve...  \n",
      "3  check maha energy website powerex mh c f charg...  \n",
      "4  reviewed quite bit combo player hesitant due u...  \n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load and inspect the dataset\n",
    "# Load datasets\n",
    "train_df = pd.read_csv('processed_train_df.csv', header=None)\n",
    "test_df = pd.read_csv('processed_test_df.csv', header=None)\n",
    "\n",
    "# Assign column names\n",
    "train_df.columns = ['label', 'title', 'review']\n",
    "test_df.columns = ['label', 'title', 'review']\n",
    "\n",
    "# Inspect datasets\n",
    "print(\"Training Data Sample:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nTesting Data Sample:\")\n",
    "print(test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3840cf78-d019-4562-9471-64c3f51caeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training set: [1 0]\n",
      "Unique labels in testing set: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Preprocess the data\n",
    "def preprocess_data(train_df, test_df):\n",
    "    # Drop rows with missing reviews\n",
    "    train_df = train_df.dropna(subset=['review'])\n",
    "    test_df = test_df.dropna(subset=['review'])\n",
    "\n",
    "    # Map labels\n",
    "    train_df['label'] = train_df['label'].map({2: 1, 1: 0})\n",
    "    test_df['label'] = test_df['label'].map({2: 1, 1: 0})\n",
    "\n",
    "    # Replace NaN labels in the test set with 0\n",
    "    test_df['label'] = test_df['label'].fillna(0).astype(int)\n",
    "\n",
    "    # Convert labels in training set to integers\n",
    "    train_df['label'] = train_df['label'].astype(int)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train_df, test_df = preprocess_data(train_df, test_df)\n",
    "\n",
    "# Extract features and labels\n",
    "X_train, y_train = train_df['review'], train_df['label']\n",
    "X_test, y_test = test_df['review'], test_df['label']\n",
    "\n",
    "# Verify preprocessing\n",
    "print(\"Unique labels in training set:\", y_train.unique())\n",
    "print(\"Unique labels in testing set:\", y_test.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb15ab12-bb24-42b4-9c58-32fe58b270b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_pad: (3599904, 194)\n",
      "Shape of X_test_pad: (399989, 194)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Tokenize and pad sequences\n",
    "import pickle\n",
    "def preprocess_text(X_train, X_test, vocab_size, max_length):\n",
    "    # Convert all reviews to strings and handle NaN values\n",
    "    X_train = X_train.fillna(\"\").astype(str)\n",
    "    X_test = X_test.fillna(\"\").astype(str)\n",
    "\n",
    "    tokenizer = Tokenizer(num_words=vocab_size)\n",
    "    tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "    X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "    X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n",
    "    X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n",
    "\n",
    "    return X_train_pad, X_test_pad, tokenizer\n",
    "\n",
    "# Define parameters\n",
    "VOCAB_SIZE = 20000\n",
    "MAX_LENGTH = 194\n",
    "\n",
    "# Preprocess text data\n",
    "X_train_pad, X_test_pad, tokenizer = preprocess_text(X_train, X_test, VOCAB_SIZE, MAX_LENGTH)\n",
    "\n",
    "# Verify padded sequences\n",
    "print(\"Shape of X_train_pad:\", X_train_pad.shape)\n",
    "print(\"Shape of X_test_pad:\", X_test_pad.shape)\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b4079f-28f8-4014-b664-a722343ee4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Define the Keras model generator class\n",
    "class KerasModelGenerator:\n",
    "    \"\"\"\n",
    "    Class to encapsulate the creation of a Keras Sequential model.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, max_length):\n",
    "        \"\"\"\n",
    "        Initialize the KerasModelGenerator.\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size (int): Size of the vocabulary for the embedding layer.\n",
    "        - embedding_dim (int): Number of dimensions for word embeddings.\n",
    "        - max_length (int): Maximum sequence length.\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.max_length = max_length\n",
    "        self.model = None  # Placeholder for the generated model\n",
    "    \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Build and return a Keras Sequential model.\n",
    "        \"\"\"\n",
    "        self.model = Sequential([\n",
    "            Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.max_length),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(0.5),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.3),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb3e6be-a17e-4b0d-bf2c-523efd93c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Train and evaluate with k-fold cross-validation\n",
    "def train_and_evaluate_with_kfolds(X, y, vocab_size, embedding_dim, max_length, n_splits=5, epochs=5, batch_size=128):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y), 1):\n",
    "        print(f\"\\nStarting Fold {fold}...\")\n",
    "\n",
    "        # Split data into training and validation for this fold\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        # Build the model\n",
    "        keras_generator = KerasModelGenerator(vocab_size, embedding_dim, max_length)\n",
    "        model = keras_generator.build()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=1\n",
    "        )\n",
    "        model.save(f'model_fold_{fold}.h5')\n",
    "        # Evaluate on validation data\n",
    "        y_val_pred_prob = model.predict(X_val)\n",
    "        y_val_pred = (y_val_pred_prob > 0.5).astype(int)\n",
    "\n",
    "        # Collect metrics\n",
    "        fold_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        fold_metrics.append(fold_accuracy)\n",
    "\n",
    "        print(f\"Fold {fold} Accuracy: {fold_accuracy:.4f}\")\n",
    "        print(f\"Classification Report for Fold {fold}:\\n\", classification_report(y_val, y_val_pred, target_names=['Negative', 'Positive']))\n",
    "\n",
    "        # Clear TensorFlow session and release memory\n",
    "        from tensorflow.keras import backend as K\n",
    "        K.clear_session()\n",
    "        import gc\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute average metrics\n",
    "    avg_metrics = {\n",
    "        \"accuracy\": np.mean(fold_metrics)\n",
    "    }\n",
    "    print(\"\\nAverage Metrics Across Folds:\")\n",
    "    print(avg_metrics)\n",
    "    return avg_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ebdd3727-c7a9-43a4-ba60-7342f34969d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Fold 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:24:39.871317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:39.890825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:39.890857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:39.891758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 18:24:39.896292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:39.896332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:39.896346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:40.542646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:40.542684: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:40.542688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1594] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-12-05 18:24:40.542705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:923] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-05 18:24:40.542724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5404 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-12-05 18:24:40.723972: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1396762752 exceeds 10% of free system memory.\n",
      "2024-12-05 18:24:41.053102: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "   36/14063 [..............................] - ETA: 1:04 - loss: 0.7186 - accuracy: 0.5015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:24:42.047175: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14059/14063 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.8648"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:25:37.290706: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1396762752 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14063/14063 [==============================] - 75s 5ms/step - loss: 0.3177 - accuracy: 0.8648 - val_loss: 0.2944 - val_accuracy: 0.8767\n",
      "Epoch 2/3\n",
      "14063/14063 [==============================] - 70s 5ms/step - loss: 0.2810 - accuracy: 0.8836 - val_loss: 0.2872 - val_accuracy: 0.8792\n",
      "Epoch 3/3\n",
      "14063/14063 [==============================] - 71s 5ms/step - loss: 0.2466 - accuracy: 0.8993 - val_loss: 0.2963 - val_accuracy: 0.8757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:28:16.950987: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1396762752 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.8757\n",
      "Classification Report for Fold 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.87      0.88    899404\n",
      "    Positive       0.88      0.88      0.88    900548\n",
      "\n",
      "    accuracy                           0.88   1799952\n",
      "   macro avg       0.88      0.88      0.88   1799952\n",
      "weighted avg       0.88      0.88      0.88   1799952\n",
      "\n",
      "\n",
      "Starting Fold 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:28:49.802602: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1396762752 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "14063/14063 [==============================] - ETA: 0s - loss: 0.3163 - accuracy: 0.8656"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 18:29:48.773127: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1396762752 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14063/14063 [==============================] - 75s 5ms/step - loss: 0.3163 - accuracy: 0.8656 - val_loss: 0.2909 - val_accuracy: 0.8772\n",
      "Epoch 2/3\n",
      "14063/14063 [==============================] - 71s 5ms/step - loss: 0.2818 - accuracy: 0.8831 - val_loss: 0.2960 - val_accuracy: 0.8774\n",
      "Epoch 3/3\n",
      "14063/14063 [==============================] - 70s 5ms/step - loss: 0.2469 - accuracy: 0.8988 - val_loss: 0.3010 - val_accuracy: 0.8751\n",
      "Fold 2 Accuracy: 0.8751\n",
      "Classification Report for Fold 2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.89      0.88    900547\n",
      "    Positive       0.89      0.86      0.87    899405\n",
      "\n",
      "    accuracy                           0.88   1799952\n",
      "   macro avg       0.88      0.88      0.88   1799952\n",
      "weighted avg       0.88      0.88      0.88   1799952\n",
      "\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "{'accuracy': 0.8753925104669458}\n",
      "\n",
      "Final Average Metrics Across All Folds:\n",
      "{'accuracy': 0.8753925104669458}\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Call k-fold training and evaluation\n",
    "y_train = np.array(y_train)  # Ensure y_train is a NumPy array\n",
    "\n",
    "# Train with k-fold cross-validation\n",
    "avg_metrics = train_and_evaluate_with_kfolds(\n",
    "    X_train_pad, y_train,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    embedding_dim=128,\n",
    "    max_length=MAX_LENGTH,\n",
    "    n_splits=2,  # Number of folds\n",
    "    epochs=3,  # Number of epochs per fold\n",
    "    batch_size=128  # Batch size\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Average Metrics Across All Folds:\")\n",
    "print(avg_metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env_26)",
   "language": "python",
   "name": "tf_env_26"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
